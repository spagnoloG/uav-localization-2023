train:
  device: "cuda:0"
  lr: 0.0003  # learning rate
  weight_decay: 0.0005  # weight decay for optimizer
  batch_size: 2  # batch size
  num_workers: 4  # number of worker threads for dataloading
  num_epochs: 16  # number of training epochs
  shuffle_dataset: true  # shuffle dataset for each epoch
  download_dataset: false # wether to download the dataset
  
  # Dataset parameters
  train_subset_size: 1000  # size of training subset. Set to null to use full dataset
  val_subset_size: 10  # size of validation subset. Set to null to use full dataset
  
  # Miscellaneous
  plot: true  # whether to plot the outputs and ground truth during validation
  
  # Checkpoint parameters
  checkpoint_hash: e3dd9cb6e0e7ceacd1d2a051ea7155be0e457b3c  # the hash of the checkpoint
  checkpoint_epoch: 23

# must be divisible by 4 becouse of the Twins model architecture
# twins model was trained on:
# >>> config {'input_size': (3, 224, 224), 'interpolation': 'bicubic', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225), 'crop_pct': 0.9, 'crop_mode': 'center'}
sat_dataset:
  mean: [0.485, 0.456, 0.406] 
  std: [0.229, 0.224, 0.225]
  patch_w: 512
  patch_h: 512
  zoom_level: 16 # satellite dataset zoom level
  root_dir: "./sat"

drone_dataset:
  mean: [0.485, 0.456, 0.406] 
  std: [0.229, 0.224, 0.225]
  patch_w: 128
  patch_h: 128
  root_dir: "./drone"
  rotation_deg: 360 # 360 means no rotation, 180 means 2 rotations, etc.

val:
  device: "cuda:0"
  checkpoint_hash:  c5a6b120d565f364b3aa4038047a51ab1d357ec6  # the hash of the checkpoint
  checkpoint_epoch: 23
  val_subset_size: null  # size of validation subset. Set to null to use full dataset
  batch_size: 2  # batch size
  num_workers: 4  # number of worker threads for dataloading
  download_dataset: false # wether to download the dataset
  plot: true 
